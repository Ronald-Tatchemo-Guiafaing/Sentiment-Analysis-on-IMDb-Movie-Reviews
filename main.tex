\documentclass{article}

% Required packages
\usepackage{graphicx}     % For inserting images
\usepackage{lipsum}       % For generating dummy text
\usepackage[margin=1in,left=1.2in,includefoot]{geometry}  % Page layout
\usepackage{ragged2e}     % For justified text
\usepackage{setspace}      % For line spacing

% Title information
\title{\textbf{Master's Degree in Computer Engineering for Robotic and Smart Industry \\ A.Y. 2023/2024 \\ Sentiment Analysis on IMDb Movie Reviews}}
\author{\textbf{Tatchemo Guiafaing Ronald \\ VR512344 \\ University of Verona}}
\date{2nd August 2024} % Date format correction

\begin{document}

% Use one-and-a-half line spacing for readability
\setstretch{1.5}

\justifying

% Title presentation
\maketitle

% Table of Contents
\tableofcontents

\newpage

% Section 1: Motivation and Rationale
\section{Motivation and Rationale}

This machine learning project, titled “Sentiment Analysis on IMDb Movie Reviews,” falls within the established research themes of Natural Language Processing (NLP), particularly sentiment analysis and opinion mining. It addresses the well-documented problem of extracting subjective information (opinions and sentiments) from large volumes of textual data, specifically movie reviews on the IMDb platform. By using a classifier, we aim to accurately predict the sentiment of other unseen textual data, specifically other movie reviews.

In my opinion, the significance of this project stems from its potential impact on understanding public opinion. By analyzing the sentiment expressed in movie reviews, the project can provide valuable insights into public perception of various aspects of films, ranging from plot and acting to social themes and cultural representation. 

This information holds significant value for:
\begin{itemize}
    \item Studios and filmmakers: gauging audience reception, informing creative decisions in future productions, and identifying effective marketing strategies.
    \item Researchers: studying audience preferences, analyzing cultural trends, and investigating the impact of media on society.
    \item Individual consumers: making informed decisions about movie choices based on the broader sentiment expressed by other viewers.
\end{itemize}

\newpage

% Section 2: State of the Art
\section{State of the Art}

Looking at the leaderboard, it’s evident that the current state of the art for sentiment analysis tasks are transformers and, in some cases, LSTMs. XLNet \cite{yang2019xlnet}, an unsupervised language representation learning method that employs Transformer-XL as the backbone model, sits at the top with an accuracy of 96.21, and in the top 10, we find several models based on BERT (Bidirectional Encoder Representations from Transformers) \cite{devlin2019bert}, all with an accuracy greater than 95. Other models with 90+ accuracy use neural networks, particularly LSTMs and RNNs.

To tackle the sentiment analysis task, however, I chose to steer away from the state-of-the-art models and opted for traditional machine learning models, including:
\begin{itemize}
    \item Naive Bayes
    \item Logistic Regression
    \item Support Vector Machines (SVM)
\end{itemize}

These simpler models are less computationally expensive to run than deep learning models and require a shorter training phase while still delivering good results on sentiment analysis tasks.

\newpage

% Section 3: Objectives
\section{Objectives}

The general objective of the project is to develop a machine learning model for sentiment analysis on IMDb movie reviews, aiming to classify user sentiments as positive or negative. To achieve this, it is paramount to address smaller “sub-problems” leading to specific objectives. For example, preprocessing the dataset to remove noise generated by unnecessary or erroneous words is fundamental to achieving the general objective.

\newpage

% Section 4: Methodology
\section{Methodology}

To develop this project, I used the Python programming language, specifically version 3.12, although it works on all Python 3.6+ versions. This language is widely employed for solving NLP problems and boasts a large community that has built tools and libraries that facilitated my work. The primary libraries used include:

\begin{itemize}
    \item \textbf{pandas}: A powerful and flexible open-source data analysis and manipulation tool, used for handling the dataset.
    \item \textbf{scikit-learn}: An open-source machine learning library supporting various supervised and unsupervised learning methods, essential for model training, evaluation, and data preprocessing.
    \item \textbf{Jupyter Notebook}: A notebook authoring application allowing for fast, interactive coding and visualization.
    \item \textbf{NLTK}: A platform for building programs with human language data. It provides tools for classification, tokenization, stemming, tagging, and more.
    \item \textbf{NumPy}: A core package for scientific computing in Python, which enables fast operations on array data.
    \item \textbf{Matplotlib}: A library for creating static, animated, and interactive visualizations in Python.
\end{itemize}

The implemented pipeline began with storing the dataset in a pandas DataFrame (50000, 2), dividing it into features \(X\) and the target variable \(y\). The sentiment “negative” was mapped to 0 and “positive” to 1. The next step involved splitting the dataset into training and testing sets (80/20 split).

During the preprocessing phase, regular expressions (regex) were employed to handle corrupt reviews by removing HTML tags and other unwanted features. In the feature extraction phase, the Bag-of-Words technique was used, implemented through the \texttt{CountVectorizer} class from scikit-learn. Only the 5000 most common words were retained, resulting in a \( (50000, 5000) \) Bag-of-Words matrix.

Finally, in the classification phase, the models were trained on the training set and tested on the test set, including:
\begin{itemize}
    \item \textbf{MultinomialNB}
    \item \textbf{Logistic Regression}
    \item \textbf{SGDClassifier with loss='log\_loss'}
    \item \textbf{LinearSVC}
    \item \textbf{SGDClassifier with loss='hinge'}
\end{itemize}

\newpage

% Section 5: Experiments and Results
\section{Experiments \& Results}

The performance of each classifier was measured qualitatively by examining specific reviews predicted correctly and incorrectly. This qualitative measurement revealed that classifiers struggled with long, ambiguous reviews.

Quantitative performance metrics such as accuracy, precision, recall, and F1-score were computed using scikit-learn's classification report and confusion matrix, providing insights into the classifiers' effectiveness in sentiment analysis.

\newpage

% Section 6: Conclusions
\section{Conclusions}

This project successfully performed sentiment analysis on IMDb movie reviews using classifiers such as MultinomialNB, LinearSVC, LogisticRegression, and SGDClassifiers. The methodology included preprocessing with regex and NLTK, as well as Bag-of-Words feature extraction with scikit-learn. The analysis showed the models' strength in classifying sentiments. 

Future work could explore advanced tokenization techniques, alternative feature extraction methods (e.g., TF-IDF), and incorporation of deep learning models for enhanced sentiment analysis.

% Bibliography
\begin{thebibliography}{9}
\bibitem{yang2019xlnet} Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. Salakhutdinov, and Q. V. Le, “XLNet: Generalized Autoregressive Pretraining for Language Understanding”. 2020.
\bibitem{devlin2019bert} J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”. 2019.
\end{thebibliography}

% Tools used for writing this report
\newpage
\section*{Tools Used for Writing This Report}
\begin{itemize}
    \item \url{https://www.latex-project.org}
    \item \url{https://www.languagetool.org}
\end{itemize}

\end{document}